import logging
import requests
import time
from typing import Dict, Any, Optional, List
from dataclasses import dataclass

# Setup basic logging for clear output and error handling
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


@dataclass
class ParserConfig:
    """
    Configuration for the price-stock parser.
    This allows easy modification of URLs, selectors, and request parameters
    without altering core logic.
    """
    base_url: str
    product_path: str = "/product/{sku}"  # Path template for product pages
    price_selector: str = ".price-value"  # CSS selector for price element
    stock_selector: str = ".stock-status"  # CSS selector for stock element
    user_agent: str = "Mozilla/5.0 (compatible; mvp-price-stock-parser/1.0)"
    request_timeout: int = 10  # Seconds to wait for a response
    max_retries: int = 3  # Maximum number of retries for failed requests
    retry_delay_seconds: int = 5  # Seconds to wait between retries


class ProductParser:
    """
    Parses product price and stock information from a given URL.
    Encapsulates web fetching and (placeholder) parsing logic.
    """
    def __init__(self, config: ParserConfig):
        self._config = config
        self._session = requests.Session()
        self._session.headers.update({'User-Agent': self._config.user_agent})

    def _fetch_page(self, url: str) -> Optional[str]:
        """
        Fetches the HTML content of a given URL with retry logic.
        Returns the HTML content as a string or None on failure.
        """
        for attempt in range(self._config.max_retries):
            try:
                logger.info(f"Fetching URL: {url} (Attempt {attempt + 1}/{self._config.max_retries})")
                response = self._session.get(url, timeout=self._config.request_timeout)
                response.raise_for_status()  # Raises HTTPError for bad responses (4xx or 5xx)
                return response.text
            except requests.exceptions.RequestException as e:
                logger.warning(f"Failed to fetch {url}: {e}")
                if attempt < self._config.max_retries - 1:
                    logger.info(f"Retrying in {self._config.retry_delay_seconds} seconds...")
                    time.sleep(self._config.retry_delay_seconds)
                else:
                    logger.error(f"Max retries exceeded for {url}.")
        return None

    def parse_product(self, sku: str) -> Optional[Dict[str, Any]]:
        """
        Parses price and stock for a given SKU.
        This method currently uses placeholder values as the actual parsing logic
        (e.g., using BeautifulSoup and CSS selectors) depends on the specific
        structure of the target website, which was not provided in the order description.
        """
        product_url = f"{self._config.base_url}{self._config.product_path.format(sku=sku)}"
        html_content = self._fetch_page(product_url)

        if not html_content:
            return None

        # Placeholder for actual HTML parsing logic.
        # In a real implementation, a library like BeautifulSoup4 would be used here:
        # from bs4 import BeautifulSoup
        # soup = BeautifulSoup(html_content, 'html.parser')
        # price_element = soup.select_one(self._config.price_selector)
        # stock_element = soup.select_one(self._config.stock_selector)
        # price = price_element.get_text(strip=True) if price_element else "N/A"
        # stock = stock_element.get_text(strip=True) if stock_element else "N/A"

        logger.info(f"Content fetched for SKU {sku}. (Parsing logic is a placeholder)")
        # Simulating parsed data:
        price = "123.45"
        stock = "In Stock"

        return {
            "sku": sku,
            "url": product_url,
            "price": price,
            "stock": stock,
            "parsed_successfully": True,
        }


def process_skus(skus: List[str], config: ParserConfig) -> List[Dict[str, Any]]:
    """
    Orchestrates the parsing of a list of SKUs using the configured parser.
    Returns a list of dictionaries containing parsed or error data for each SKU.
    """
    parser = ProductParser(config)
    results = []
    for sku_item in skus:
        logger.info(f"Processing SKU: {sku_item}")
        product_data = parser.parse_product(sku_item)
        if product_data:
            results.append(product_data)
        else:
            logger.error(f"Failed to parse data for SKU: {sku_item}")
            results.append({"sku": sku_item, "parsed_successfully": False})
    return results


if __name__ == "__main__":
    # Example Usage:
    # This section demonstrates how the parser would be initialized and used.
    # Replace with actual website base URL and specific CSS selectors.
    parser_config = ParserConfig(
        base_url="https://example.com",  # Placeholder: use your target website's base URL
        price_selector="span.product-price",  # Placeholder: use actual CSS selector for price
        stock_selector="div.product-stock",  # Placeholder: use actual CSS selector for stock
    )

    # List of SKUs to process. In a real scenario, this might come from a file or database.
    skus_to_process = ["PRODUCT123", "ITEM456", "SKU789"]

    logger.info("Starting product parsing process...")
    parsed_products = process_skus(skus_to_process, parser_config)

    logger.info("\n--- Parsing Results ---")
    for product in parsed_products:
        logger.info(product)
    logger.info("Product parsing process finished.")